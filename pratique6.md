### Apache Spark Streaming 

---

ğŸš€ **Introduction Ã  Apache Spark Streaming**

Bienvenue dans ce tutoriel interactif sur Apache Spark Streaming ! Nous allons plonger dans le monde fascinant du traitement des flux de donnÃ©es en temps rÃ©el. PrÃ©parez-vous Ã  transformer des flots de donnÃ©es en informations prÃ©cieuses avec Apache Spark. ğŸŒŸ

---

### ğŸ›  PrÃ©requis

Avant de commencer, assurez-vous d'avoir :

1. **Apache Spark** : InstallÃ© et configurÃ© sur votre machine. Spark est le moteur qui alimente nos explorations de donnÃ©es.
2. **Netcat (ncat)** : Outil pour tester des flux de donnÃ©es. Il nous permettra d'envoyer des donnÃ©es Ã  notre application Spark en temps rÃ©el.

---

### ğŸ“– Guide Pas Ã  Pas

#### ğŸ”¹ **Terminal 1: Configuration de Spark Streaming**

```scala
// ğŸŒŸ Importations pour commencer
import org.apache.spark._
import org.apache.spark.streaming._

// ğŸ© CrÃ©ation du contexte de streaming - Votre baguette magique pour les donnÃ©es en temps rÃ©el
val ssc = new StreamingContext(sc, Seconds(3))

// ğŸ“¡ Ã‰coute des donnÃ©es sur localhost:9988 - OÃ¹ la magie commence
val lines = ssc.socketTextStream("localhost", 9988)

// ğŸ“– Transformation des lignes en mots - DÃ©couper les donnÃ©es en piÃ¨ces comprÃ©hensibles
val words = lines.flatMap(_.split(" "))

// ğŸ”¢ Comptage des mots - Trouvez la valeur dans le chaos
val pairs = words.map(word => (word, 1))
val wordCounts = pairs.reduceByKey(_ + _)

// ğŸ‘€ Affichage des rÃ©sultats - Voyez ce que vous avez accompli
wordCounts.print()

// ğŸš€ Lancement du traitement - Mettez votre casque, c'est parti !
ssc.start()
```

---

#### ğŸ”¹ **Terminal 2: Envoi de DonnÃ©es avec Netcat**

```bash
ncat -lk 9988
```
ou
```bash
nc -lk 9988 
```
# Lien de tÃ©lÃ©chargement de ncat ou nc via le site de nmap : https://nmap.org/ncat/ 

ğŸ“ **Note :** C'est ici que vous pouvez Ã©crire les mots qui seront ensuite traitÃ©s par votre application Spark Streaming. Chaque ligne que vous entrez sera envoyÃ©e Ã  Spark, qui comptera les mots en temps rÃ©el.

---

### ğŸ¨ RÃ©sumÃ©

# ğŸ”¹ **Terminal 1: Programme scala**

```scala
import org.apache.spark._
import org.apache.spark.streaming._
val ssc = new StreamingContext(sc, Seconds(3))
val lines = ssc.socketTextStream("localhost", 9988)
val words = lines.flatMap(_.split(" "))
// Count each word in each batch
val pairs = words.map(word => (word, 1))
val wordCounts = pairs.reduceByKey(_ + _)
wordCounts.print()
// Start the computation
ssc.start()
```
# ğŸ”¹ **Terminal 2: Envoi de DonnÃ©es avec Netcat**

```bash
ncat -lk 9988
```
ou
```bash
nc -lk 9988 
```


Bon travail ! ğŸš€
