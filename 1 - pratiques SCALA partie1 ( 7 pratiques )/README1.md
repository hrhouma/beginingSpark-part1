# Table de matières

**Pratique 1. Opérations de Base avec Spark**
- Objectif: Découvrir les fonctionnalités fondamentales de Spark, y compris la création et la manipulation basique des RDD.

**Pratique 2. RDD et Autres Opérations de Base**
- Objectif: Explorer des opérations avancées sur les RDD, telles que sample, union, intersection, et comprendre l'utilisation de cogroup et fullOuterJoin.

**Pratique 3. RDD vers DataFrame vers Spark SQL**
- Objectif: Illustrer le processus de conversion des RDD en DataFrames, puis montrer comment effectuer des requêtes SQL sur ces DataFrames pour manipuler et interroger des données.

**Pratique 4. Comparaison entre RDD, DataFrame, et Dataset + Manipulation de Fichiers JSON et CSV**
- Objectif: Démontrer les différences et les cas d'utilisation des RDD, DataFrames, et Datasets, et montrer comment charger, manipuler, et interroger des données à partir de fichiers JSON et CSV.

**Pratique 5. Conversion d'un RDD en DataFrame puis en Dataset**
- Objectif: Montrer étape par étape comment transformer un RDD en DataFrame et ensuite en Dataset, en utilisant Scala et PySpark pour les exemples.

**Pratique 6. Apache Spark Streaming**
- Objectif: Ce tutoriel offre une introduction à Apache Spark Streaming pour le traitement des flux de données en temps réel. Il comprend la configuration d'un contexte de streaming Spark, l'écoute des données sur un port spécifique, la transformation des lignes en mots, le comptage des mots, et l'affichage des résultats en temps réel. Utilisant Scala, ce guide inclut également des instructions pour envoyer des données via Netcat, un outil essentiel pour tester des flux de données en interaction avec Spark Streaming.

**Pratique 7. Apache Spark Streaming - Approfondissement avec Analyse de Sentiment**
- Objectif: Approfondir l'expérience d'Apache Spark Streaming en intégrant l'intelligence artificielle pour une analyse de sentiment en temps réel des tweets, utilisant des techniques avancées telles que la régression logistique pour le traitement du langage naturel. Ce tutoriel vous guidera à travers les étapes nécessaires pour configurer et exécuter une analyse de sentiment sur des flux de tweets en temps réel, en utilisant un modèle d'apprentissage automatique entraîné sur un jeu de données labellisé. Vous apprendrez à préparer un script Python pour le streaming de données, l'analyse de sentiment, et la visualisation des résultats en temps réel, offrant une compréhension pratique de l'analyse de données en flux avec PySpark.