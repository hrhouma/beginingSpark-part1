# Table de matières

**Pratique 1. Opérations de Base avec Spark**
- Objectif: Découvrir les fonctionnalités fondamentales de Spark, y compris la création et la manipulation basique des RDD.

**Pratique 2. RDD et Autres Opérations de Base**
- Objectif: Explorer des opérations avancées sur les RDD, telles que sample, union, intersection, et comprendre l'utilisation de cogroup et fullOuterJoin.

**Pratique 3. RDD vers DataFrame vers Spark SQL**
- Objectif: Illustrer le processus de conversion des RDD en DataFrames, puis montrer comment effectuer des requêtes SQL sur ces DataFrames pour manipuler et interroger des données.

**Pratique 4. Comparaison entre RDD, DataFrame, et Dataset + Manipulation de Fichiers JSON et CSV**
- Objectif: Démontrer les différences et les cas d'utilisation des RDD, DataFrames, et Datasets, et montrer comment charger, manipuler, et interroger des données à partir de fichiers JSON et CSV.

**Pratique 5. Conversion d'un RDD en DataFrame puis en Dataset**
- Objectif: Montrer étape par étape comment transformer un RDD en DataFrame et ensuite en Dataset, en utilisant Scala et PySpark pour les exemples.

**Pratique 6. Apache Spark Streaming**
- Objectif: Ce tutoriel offre une introduction à Apache Spark Streaming pour le traitement des flux de données en temps réel. Il comprend la configuration d'un contexte de streaming Spark, l'écoute des données sur un port spécifique, la transformation des lignes en mots, le comptage des mots, et l'affichage des résultats en temps réel. Utilisant Scala, ce guide inclut également des instructions pour envoyer des données via Netcat, un outil essentiel pour tester des flux de données en interaction avec Spark Streaming.

**Pratique 7. Apache Spark Streaming - Approfondissement**
- Objectif: Poursuivre l'exploration d'Apache Spark Streaming en approfondissant les concepts et les techniques de traitement des flux de données en temps réel. Ce tutoriel interactif se concentre sur l'analyse de sentiment en temps réel pour les tweets, illustrant la configuration de Spark Streaming, la création de contextes de streaming avancés, et l'exploration de nouvelles façons d'analyser et de visualiser les données en temps réel. Avec des exemples pratiques et des scénarios d'utilisation, ce guide montre comment exploiter pleinement le potentiel de Spark dans le traitement de flux de données dynamiques, en utilisant des mots-clés tels que love, trump, media, war, obama, et d'autres pour tester l'analyse de sentiment.